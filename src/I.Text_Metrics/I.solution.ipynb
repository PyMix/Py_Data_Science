{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up\n",
    "%reset -f\n",
    "\n",
    "# Importing libraries\n",
    "from os import makedirs, path\n",
    "from lzma import decompress\n",
    "from requests import get\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. `Data Exploration`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to project folder:\t data/war_peace_processed.txt\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/DsMix/Books/main/war_peace_processed.txt.xz'\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "# Create data folder if not exists\n",
    "if not path.exists('data'):\n",
    "    makedirs(data_dir)\n",
    "\n",
    "data_path = data_dir + \\\n",
    "  url.split(\"/\")[-1].rsplit('.', 1)[0]\n",
    "\n",
    "# Download file\n",
    "response = get(url)\n",
    "content = response.content\n",
    "unzip_file = decompress(content)\n",
    "\n",
    "# Save file to data folder\n",
    "with open(data_path, 'wb') as file:\n",
    "    file.write(unzip_file)\n",
    "    print(f'Data saved to project folder:\\t {data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2. Data overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\nв\\nдва\\nраза\\nкороче\\nи\\nв\\nпять\\nраз\\nинтереснее'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read file from data folder\n",
    "with open(data_path, 'r') as file:\n",
    "  data = file.read()\n",
    "\n",
    "display(data[:43])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.3. Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['первая']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split by chapters\n",
    "\n",
    "chapters = data.split('[new chapter]')\n",
    "chapters_words = []\n",
    "\n",
    "for each in chapters:\n",
    "  words = [el for el in each.split('\\n') if el]\n",
    "  chapters_words.append(words)\n",
    "\n",
    "chapters_words[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. `Data Analysis`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1. Word Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapters:\t 171\n",
      "Words all:\t 299909\n",
      "Words unique:\t 38210\n"
     ]
    }
   ],
   "source": [
    "words_all = []\n",
    "chapters_words_count = {}\n",
    "\n",
    "for each in chapters_words:\n",
    "  # add all words from each chapter to words_all\n",
    "  words_all.extend(each)  \n",
    "  \n",
    "words_unique = set(words_all) # unique words\n",
    "\n",
    "words_count = len(words_all)\n",
    "words_unique_count = len(words_unique)\n",
    "chapters_count = len(chapters)\n",
    "\n",
    "print('Chapters:\\t', chapters_count)\n",
    "print('Words all:\\t', words_count)\n",
    "print('Words unique:\\t', words_unique_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2. Frequency of Words in the Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 14592), ('--', 9680), ('в', 6997), ('не', 5922), ('он', 5266)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_freq = {}\n",
    "\n",
    "for el in words_all:\n",
    "  if el not in data_freq:\n",
    "    data_freq[el] = 1\n",
    "  else:\n",
    "    data_freq[el] += 1\n",
    "\n",
    "# Show most frequent words in the text\n",
    "sorted(data_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3. Frequency of Words in Each Document (Chapter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_words_freq = []\n",
    "\n",
    "for i, chapter in enumerate(chapters_words):\n",
    "  chapters_words_freq.append({})\n",
    "  for word in chapter:\n",
    "    if word not in chapters_words_freq[i]:\n",
    "      chapters_words_freq[i][word] = 1\n",
    "    else:\n",
    "      chapters_words_freq[i][word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check frequency of word in a chapter\n",
    "\n",
    "def get_word_freq(word, chapter_index):\n",
    "  if not 0 <= chapter_index < chapters_count:\n",
    "    print('Chapter index out of range')\n",
    "    return\n",
    "  if word not in chapters_words_freq[chapter_index]:\n",
    "    return 0\n",
    "  return chapters_words_freq[chapter_index][word]\n",
    "\n",
    "get_word_freq('анна', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.4. **`TF`** (term frequency)\n",
    "\n",
    "<p>shows how often a term occurs in a document (chapter)</p>\n",
    "\n",
    "This measure is used to `score` the `relevance` of a term in a document (chapter)\n",
    "\n",
    "$$ tf*{word, chapter} = \\frac {n*{word, chapter}} {n\\_{chapter}}$$\n",
    "\n",
    "where\n",
    "\n",
    "- $tf_{word, chapter}$ - term frequency of the word in the chapter\n",
    "- $n_{word, chapter}$ - number of times the word occurs in the chapter, $n_{word, chapter} \\leq n_{chapter}$\n",
    "- $n_{chapter}$ - number of words in the chapter,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = []\n",
    "for i, chapter in enumerate(chapters_words_freq):\n",
    "  tf.append({})\n",
    "  for word in chapter:\n",
    "    tf[i][word] = chapters_words_freq[i][word] / len(chapters_words[i])\n",
    "    tf[i][word] = tf[i][word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007358"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result\n",
    "\n",
    "def get_tf_word(word='', chapter_index=''):\n",
    "  if chapter_index == '':\n",
    "    chapter_index = input('Enter a chapter index: ')  \n",
    "  try:\n",
    "    if type(chapter_index) == str:\n",
    "      chapter_index = int(chapter_index)\n",
    "  except:\n",
    "    return 'Chapter index must be an integer'    \n",
    "  if chapter_index > len(tf) - 1:\n",
    "    return 'Chapter index must be less than ' + str(chapters_count)\n",
    "  if word == '': \n",
    "    word = input('Enter a word: ')\n",
    "  word = word.lower().strip()\n",
    "  if word not in tf[chapter_index]:\n",
    "    return 'Word not found in the chapter[' + str(chapter_index) + ']'  \n",
    "  return tf[chapter_index][word]\n",
    "\n",
    "\n",
    "round(get_tf_word('гостья', 15) , 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.5. **`DF`** (Document Frequency)\n",
    "\n",
    "<p>represents how widespread a term is across a collection of documents (chapters)</p>\n",
    "\n",
    "- `Absolute DF`:<br>\n",
    "  counts the number of documents (chapters) that contain the term (word).\n",
    "  $$ df*{\\text{word}}^{\\text{abs}} = N*{\\text{word}} $$\n",
    "\n",
    "- `Normalized DF`:<br>\n",
    "  gives the proportion of documents (chapters) in the corpus (book) that contain the term (word).\n",
    "  $$ df*{\\text{term}}^{\\text{norm}} = \\frac{N*{\\text{word}}}{N} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $df_{\\text{term}}^{\\text{abs}}$ - absolute document frequency of the term (word)\n",
    "- $df_{\\text{term}}^{\\text{norm}}$ - normalized document frequency of the term (word)\n",
    "- $N_{\\text{term}}$ - number of documents (chapters) containing the term (word)\n",
    "- $N$ - total number of documents (chapters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate if_abs and df_norm\n",
    "\n",
    "df_abs = {}\n",
    "df_norm = {}\n",
    "\n",
    "\n",
    "for word in words_unique:\n",
    "  count = 0\n",
    "  for document in chapters_words_freq:\n",
    "    if word in document:\n",
    "      count += 1\n",
    "  df_abs[word] = count\n",
    "  df_norm[word] = count / chapters_count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('df normalized', 'человек', 0.672514619883041)\n",
      "('df absolute', 'анна', 32)\n"
     ]
    }
   ],
   "source": [
    "# Check the result\n",
    "\n",
    "def get_df_word(word, N=False):\n",
    "  word = word.lower().strip()  \n",
    "  if N == False and word in df_abs:\n",
    "    return 'df absolute', word, df_abs[word], \n",
    "  if N == True and word in df_norm: \n",
    "    return 'df normalized', word, df_norm[word]\n",
    "  return 'Word not found'\n",
    "\n",
    "print(get_df_word('человек', True))\n",
    "print(get_df_word('анна'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.6. **`IDF`** (inverse document frequency)\n",
    "\n",
    "<p>A measure used to calculate the importance of a term relative to its frequency across multiple documents (chapters).</p>\n",
    "\n",
    "- `Raw idf`:\n",
    "  <p>Used to score the importance of a term across numerous documents.</p>\n",
    "$$idf_{term} = \\frac{N}{df_{term}}$$\n",
    "\n",
    "- `Logarithmic idf`:\n",
    "  <p>Used to dampen the effects of terms with very high or very low DF.</p>  \n",
    "$$idf_{term} = \\log\\left(\\frac{N}{df_{term}}\\right)$$\n",
    "\n",
    "- `Smoothed idf`:\n",
    "  <p>Used to avoid division by zero.</p>\n",
    "\n",
    "$$idf_{term} = \\log\\left(\\frac{N}{1 + df_{term}}\\right)$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $idf_{term}$ - inverse document frequency of the term.\n",
    "- $df\\_{term} $ - document frequency of the term.\n",
    "- $N$ - total number of documents (chapters) in the corpus (book).\n",
    "- $\\log$ - natural logarithm: $\\log_e$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.7. **`TF-IDF`** (term frequency - inverse document frequency)\n",
    "\n",
    "<p>Measure of importance of a word to a document in a collection or corpus</p>\n",
    "\n",
    "$tf-idf = \\text{term frequency} \\times \\text{inverse document frequency}$\n",
    "\n",
    "$$ tf-idf*{term, chapter} = tf*{term, chapter} \\times \\log\\left(\\frac{N}{df\\_{term}}\\right) $$\n",
    "\n",
    "where\n",
    "\n",
    "- $tf-idf_{term, chapter}$ - the tf-idf of the term in the document (chapter).\n",
    "- $tf_{term, chapter}$ - the term frequency of the term in the document (chapter).\n",
    "- $df_{word}$ - the absolute document frequency of the term.\n",
    "- $N$ - the total number of documents (chapters) in the corpus (book).\n",
    "- $\\log$ - the natural logarithm: $\\log_e$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = []\n",
    "N = chapters_count\n",
    "\n",
    "for i, chapter in enumerate(chapters_words_freq):\n",
    "  tf_idf.append({})\n",
    "  for word in chapter:\n",
    "    tf_idf[i][word] = tf[i][word] * log(N / df_abs[word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011067"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result\n",
    "\n",
    "def get_tf_idf_word(word, chapter_index):\n",
    "  if not 0 <= chapter_index < chapters_count:\n",
    "    print('Chapter index out of range')\n",
    "    return\n",
    "  word = word.lower().strip()\n",
    "  if word not in tf_idf[chapter_index]:\n",
    "    return 'Word not found in the chapter[' + str(chapter_index) + ']'\n",
    "  return tf_idf[chapter_index][word]\n",
    "\n",
    "target_word = 'анна'\n",
    "target_chapter = 4\n",
    "round(get_tf_idf_word(target_word, target_chapter), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t 0.014655\t павловна\n",
      "2\t 0.009814\t анна\n",
      "3\t 0.006948\t функе\n"
     ]
    }
   ],
   "source": [
    "# Get top n tf-idf values for a chapter\n",
    "\n",
    "n = 3 # number of top values\n",
    "target_chapter = 3\n",
    "\n",
    "sorted_tf_idf = sorted(tf_idf[target_chapter].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print top 3 tf-idf values\n",
    "for i, (term, score) in enumerate(sorted_tf_idf[:n]):\n",
    "    round_score = f\"{score:.6f}\"\n",
    "    print(f\"{i+1}\\t {round_score}\\t {term}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
